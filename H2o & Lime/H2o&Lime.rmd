---
title: "H2o & Lime"
author: "Teo Lo Piparo"
date: "27/1/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Task 2: Import Libraries
library(tidyverse)
library(readxl)
library(h2o)
library(lime)
library(recipes) 
```

```{r}
# Task 2.1: Load the IBM Employee Attrition Data
getwd()
dataRaw <- read_csv("EmployeeAttrition.csv")
dataRaw[1:10,]
```


```{r}
# Task 3: Pre-process Data Using Recipes
data <- dataRaw %>%
  mutate_if(is.character, as.factor) %>%
  select(Attrition, everything())

recipe_obj <- data %>%
  recipe(formula = Attrition ~ .) %>% #specify formula
  step_rm(EmployeeNumber) %>% #remove columns that are not needed like the index
  step_zv(all_predictors()) %>% #emove variables that contain only a single value.
  step_center(all_numeric()) %>% #normalize numeric data to have a mean of zero.
  step_scale(all_numeric()) %>% #normalize numeric data to have a standard deviation of one
  prep(data = data)

data <- bake(recipe_obj, new_data = data) #For a recipe with at least one preprocessing operations that has been trained by prep.recipe(), apply the computations to new data.
glimpse(data) # transpose view of tibble

```


```{r}
# Task 4.0: Start H2O Cluster and Create Train/Test Splits
h2o.init(max_mem_size = "4g")

```

```{r}
# Task 4.1: Create Training and Test Sets
set.seed(1234)
data_h2o <- as.h2o(data)

splits <- h2o.splitFrame(data_h2o, c(.7, .15), seed = 1234)

train <- h2o.assign(splits[[1]], "train")
valid <- h2o.assign(splits[[2]], "valid")
test <- h2o.assign(splits[[3]], "test")


```

```{r}
# Task 5: Run AutoML to Train and Tune Models
y <- "Attrition"
x <- setdiff(names(train), y)

aml <- h2o.automl(x = x, y = y,
                  training_frame = train,
                  leaderboard_frame = valid,
                  max_runtime_secs = 60)

```

```{r}
# Task 6: Leaderboard Exploration
lb <- aml@leaderboard #leaderboard created by the h2o.automl
print(lb, n = nrow(lb))
#best <- aml@leader #it takes the best model of the leaderboard
model_ids <-as.data.frame(aml@leaderboard$model_id)[,1]
best_model <- h2o.getModel(grep("StackedEnsemble_BestOfFamily", model_ids, value=TRUE)[1])
```



```{r}
# Task 7: Model Performance Evaluation
perf <- h2o.performance(best_model, newdata = test)
optimal_treshold <- h2o.find_threshold_by_max_metric(perf, "f1")
metrics <- as.data.frame(h2o.metric(perf, optimal_treshold))
t(metrics)

null_error_rate <- metrics$tns / (metrics$tps + metrics$tns + metrics$fps + metrics$fns)

```


```{r}
# Task 9: Local Interpretable Model-Agnostic Explanations 
explainer <- lime(as.data.frame(train[, -31]), best_model, bin_continuous = F) #remove 'Attrition' column keeping only predictors
explanation <- explain(as.data.frame(test[3:10, -31]), #cherry picked rows for explaining pusposes
                       explainer = explainer,
                       kernel_width = 1,
                       n_features = 5, #max features to explain each model
                       n_labels = 1) 

plot_features(explanation)


```
